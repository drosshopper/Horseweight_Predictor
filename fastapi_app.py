# fastapi_app.py
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import joblib
import pandas as pd
import shap
import numpy as np
from scipy.spatial import distance
import uvicorn
from catboost import CatBoostRegressor

# ğŸ¯ FastAPIã‚¢ãƒ—ãƒª
app = FastAPI()

@app.get("/")
def read_root():
    return {"status": "ok"}

# ğŸŒ CORSï¼ˆHugging Faceã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://huggingface.co/spaces/drosshopper/horse-weight-predictor2"],  # æœ¬ç•ªç’°å¢ƒã§ã¯åˆ¶é™æ¨å¥¨
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“¦ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = joblib.load("models/model_cat.pkl")  # â† Renderä¸Šã®modelsãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®
explainer = shap.Explainer(model)

# ğŸ“¥ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼
class InputData(BaseModel):
    sex: int
    height: float
    waist: float
    leg: float         # â† ã“ã®1è¡Œã‚’è¿½åŠ 
    weight_age1: float
    measure: int
    daysold: int


# SHAPå€¤ã¨å¤‰åŒ–é‡ã‚’è¿”ã™ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/predict")
async def predict_with_shap(data: InputData, request: Request):
    input_df = pd.DataFrame([data.dict()])
    input_df_model = input_df.drop(columns=["leg"]) 
    shap_values = explainer(input_df_model)

    
    
    # SHAPã®å‡ºåŠ›ã‹ã‚‰å€¤ã‚’å–ã‚Šå‡ºã—
    base_value = shap_values.base_values[0]
    shap_contributions = shap_values.values[0].tolist()
    feature_names = shap_values.feature_names
    gain_pred = model.predict(input_df_model)[0]
    pred_weight = data.weight_age1 + gain_pred

    # âœ… åé¦¬ã¨ã®é¡ä¼¼åº¦è©•ä¾¡ï¼ˆãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ï¼‰
    # âœ… å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«
    input_vec = np.array([
        data.height,
        data.waist,
        data.leg,
        pred_weight
    ])

    # âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df_all = pd.read_csv("models/WeightSuggestall.csv")
    features = ["height", "waist", "leg", "result"]
    ref_df = df_all.dropna(subset=features).copy()  # å…¨é¦¬å¯¾è±¡ã«å¤‰æ›´
    X = ref_df[features].values
    
    # âœ… é‡ã¿ã®å®šç¾©ï¼ˆè‡ªç”±ã«èª¿æ•´å¯èƒ½ï¼‰
    weights = np.array([20, 20, 1, 50])
    
    # âœ… å…±åˆ†æ•£è¡Œåˆ—ã¯å…¨ä½“ã§è¨ˆç®—
    cov = np.cov(X, rowvar=False)
    inv_cov = np.linalg.inv(cov)
    
    # âœ… é‡ã¿ä»˜ããƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢é–¢æ•°
    def weighted_mahalanobis(x, y, inv_cov, weights):
        diff = (x - y) * weights
        return np.sqrt(np.dot(np.dot(diff, inv_cov), diff.T))
    
    # âœ… è·é›¢ã‚’å…¨é¦¬ã«å¯¾ã—ã¦è¨ˆç®—
    ref_df["mahalanobis"] = [
        weighted_mahalanobis(row, input_vec, inv_cov, weights) for row in X
    ]
    
    # âœ… é‡è³å‹ã¡é¦¬ã ã‘ã‹ã‚‰æœ€ã‚‚è¿‘ã„é¦¬ã‚’æŠ½å‡ºï¼ˆTOP3ï¼‰
    graded_matches = (
        ref_df[ref_df["graded_winner"] == 1]
        .sort_values("mahalanobis")
        .head(3)
    )
    
    top_matches = []
    for _, row in graded_matches.iterrows():
        top_matches.append({
            "name": row.get("name", "ä¸æ˜"),
            "distance": round(row["mahalanobis"], 3),
            "features": {
                "height": row["height"],
                "waist": row["waist"],
                "leg": row["leg"],
                "result": row["result"]
            }
        })





    return {
        "gain_pred": gain_pred,
        "base_value": base_value,
        "contributions": shap_contributions,
        "features": feature_names,
        "top_matches": top_matches  # ğŸ‘ˆ åé¦¬é¡ä¼¼åº¦TOP3ã‚’è¿½åŠ 

    }
